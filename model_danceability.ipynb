{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba76857-b572-4875-b482-a3d3517ec200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import suppress\n",
    "from zipfile import ZipFile, BadZipFile\n",
    "import os\n",
    "\n",
    "#set up Colab if detected\n",
    "with suppress(ModuleNotFoundError):\n",
    "    from google.colab import drive\n",
    "    %pip install neptune > /dev/null\n",
    "    try: #assumes repo zipped (zip -r spectrofy.zip Spectrofy -x \\*.git* \\*ipynb* \\*.mp3 \\*.pth) and uploaded\n",
    "        with ZipFile('spectrofy.zip') as zip:\n",
    "            zip.extractall()\n",
    "        os.chdir('Spectrofy')\n",
    "    except (FileNotFoundError, BadZipFile): #as fallback assumes repo uploaded to Drive (training will be slower)\n",
    "        drive.mount('/content/drive')\n",
    "        os.chdir('drive/MyDrive/Spectrofy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8320f3-fe05-4414-b0e5-6c733dc7c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune\n",
    "from getpass import getpass\n",
    "\n",
    "#set up Neptune\n",
    "log = True #enables/disables logging\n",
    "if log:\n",
    "    run = neptune.init_run( #the warning about interactive sessions can be ignored\n",
    "        api_token = getpass('Enter your Neptune API token: '),\n",
    "        project = input('Enter your Neptune project name: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff897a7d-45b4-4961-aff6-1c12981fc461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import SpectrogramsDataset\n",
    "from utils.preprocessing import transform\n",
    "from torch.utils.data import random_split\n",
    "from torch import Generator\n",
    "\n",
    "#split dataset deterministically\n",
    "spec_dir = os.path.join('data', 'spec')\n",
    "features_path = os.path.join('data', 'features.csv')\n",
    "dataset = SpectrogramsDataset(spec_dir, features_path, transform, target='danceability')\n",
    "trainset, valset, testset = random_split(dataset, [0.8, 0.1, 0.1], Generator().manual_seed(42))\n",
    "len(trainset), len(valset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687f30e-9523-4da5-b8cc-175d33fb13c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#configure batches\n",
    "loader_args = {\n",
    "    'batch_size': 32, #TODO tune with Neptune\n",
    "    'num_workers': 2,\n",
    "    'pin_memory': True,\n",
    "    'drop_last': True}\n",
    "train_loader = DataLoader(trainset, shuffle=True, persistent_workers=True, **loader_args)\n",
    "val_loader = DataLoader(valset, persistent_workers=True, **loader_args)\n",
    "test_loader = DataLoader(testset, **loader_args)\n",
    "_, channels, height, width = next(iter(train_loader))[0].shape\n",
    "\n",
    "#log dataset\n",
    "if log:\n",
    "    run['dataset'] = {\n",
    "        'target': dataset.target,\n",
    "        'train-validation-test': (\n",
    "            f'{len(trainset)}-' #whole because reshuffled at each epoch\n",
    "            f\"{loader_args['batch_size'] * len(val_loader)}-\"\n",
    "            f\"{loader_args['batch_size'] * len(test_loader)}\"),\n",
    "        'channels-height-width': f'{channels}-{height}-{width}'}\n",
    "channels, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b49fcb-5c7f-4530-9567-5250c227a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.models import DanceabilityModel\n",
    "from torch import nn, optim\n",
    "import inspect\n",
    "import importlib; from utils import models; importlib.reload(models) #for debugging purposes\n",
    "\n",
    "#configure training\n",
    "model_args = {}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DanceabilityModel(**model_args).to(device) #TODO tune with Neptune\n",
    "criterion = type('MSELoss', (nn.MSELoss,), {'__str__': lambda self : 'MSE'})()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3) #TODO tune lr with Neptune\n",
    "\n",
    "#log model\n",
    "if log:\n",
    "    run['model'] = {\n",
    "        'architecture': inspect.getsource(DanceabilityModel),\n",
    "        'arguments': model_args}\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e279f0-7d78-4be1-b3f0-94a34a27327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_params = None\n",
    "for epoch in range(999):\n",
    "\n",
    "    #train\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model(inputs.to(device))\n",
    "        loss = criterion(outputs, labels.to(device)) #estimates loss of batch with current parameters\n",
    "        optimizer.zero_grad() #resets gradient to avoid accumulation\n",
    "        loss.backward() #computes gradient of loss w.r.t. parameters\n",
    "        optimizer.step() #updates parameters to reduce loss\n",
    "        running_loss += loss.item()\n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "    print(f'[epoch {epoch:03}] train loss: {train_losses[-1]:.4f}, ', end='')\n",
    "\n",
    "    #evaluate on validation set\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    with torch.inference_mode(): #to save memory and computations\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs.to(device))\n",
    "            running_loss += criterion(outputs, labels.to(device)).item()\n",
    "    val_losses.append(running_loss/len(val_loader))\n",
    "\n",
    "    #back up best parameters\n",
    "    end = '\\n'\n",
    "    if val_losses[-1] <= min(val_losses):\n",
    "        best_params = deepcopy(model.state_dict())\n",
    "        end = ' (new best)\\n'\n",
    "    print(f'val loss: {val_losses[-1]:.4f}', end=end)\n",
    "\n",
    "    #stop early\n",
    "    patience = 3\n",
    "    with suppress(IndexError):\n",
    "        if all(np.array(val_losses[-patience:]) > val_losses[-patience-1]):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0929d-99dc-411b-81cf-562aecf08e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plot training history\n",
    "plt.plot(train_losses, label=f'Train {criterion}')\n",
    "plt.plot(val_losses, label=f'Validation {criterion}')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean loss')\n",
    "figure = plt.gcf() #will be logged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9025c9e0-296c-4842-abca-999c69a7facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "#evaluate on test set\n",
    "model.load_state_dict(best_params)\n",
    "assert not model.training\n",
    "running_loss = 0\n",
    "with torch.inference_mode():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs.to(device))\n",
    "        running_loss += F.l1_loss(outputs, labels.to(device)).item() #MAE for interpretability\n",
    "test_mae = round(running_loss/len(test_loader), ndigits=4)\n",
    "print(f'Mean absolute error on test set: {test_mae}')\n",
    "\n",
    "#log training\n",
    "if log:\n",
    "    run['training'] = {\n",
    "        'batch_size': loader_args['batch_size'],\n",
    "        'optimizer': str(optimizer),\n",
    "        'test_mae': test_mae}\n",
    "    run['training/history'].upload(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ada90-03b8-4d59-9ead-70ca0d30ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best parameters\n",
    "param_dir = os.path.join('utils', 'model_params')\n",
    "os.makedirs(param_dir, exist_ok=True)\n",
    "param_path = os.path.join(param_dir, 'danceability.pth')\n",
    "torch.save(best_params, param_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a88e2-b229-4cca-8239-03ccf8fd91bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model\n",
    "model = DanceabilityModel(**model_args)\n",
    "model.load_state_dict(torch.load(param_path, map_location='cpu'))\n",
    "model.eval()\n",
    "spec, true = testset[0]\n",
    "pred = model(spec).item()\n",
    "print(f'[danceability] true: {true:.2f}, predicted: {pred:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58ab60-cd38-468a-a4ec-a0766624e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop logging\n",
    "if log:\n",
    "    run.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
